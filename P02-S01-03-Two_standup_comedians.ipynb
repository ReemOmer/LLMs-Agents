{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c67978eb-73eb-4dc3-a05d-4cc4302870d6",
   "metadata": {},
   "source": [
    "# State altering agents: stand up comedy\n",
    "\n",
    "In this example, we are going to create two agents. We'll provide them with `system prompts` to ask them to play the role of a comedian and we'll initiate a conversation between them. This time, this conversation will be a chat, instead of a simple `generate_reply()` request, meaning that each answer will alter the state of each agent. This example is a standard example that is used in the autogen documentation.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e04d2-0ad5-460f-a69d-69b1ef19744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll always have to start by creating a llm_config object to configure our agents\n",
    "llm_config = {\n",
    "    \"model\": \"gpt-3.5-turbo\", \n",
    "    \"api_key\": \"\"\n",
    "    }\n",
    "\n",
    "# llm_config = {\n",
    "#     \"config_list\": [{\n",
    "#         \"model\": \"mistral-7b-instruct-v0.2\",\n",
    "#         \"base_url\": \"http://localhost:1234/v1\",\n",
    "#         \"api_key\": \"lm-studio\",\n",
    "#         \"price\": [0.0, 0.0]\n",
    "#         }],\n",
    "#     \"cache_seed\": None\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb4b3c1-0bb3-42a6-984e-b21dc7edd8aa",
   "metadata": {},
   "source": [
    "## Conversable Agent\n",
    "\n",
    "Let's important the ConversableAgent class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93821754-9458-4195-8b8f-9beebcfb74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3550813-4331-4ebd-a635-d86396147e6c",
   "metadata": {},
   "source": [
    "Let us now define our agents, we'll give them names, our chatGPT3.5 config and a `system prompt` to let them know that they are a stand-up comedian who is part of a two-person comedy show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6afd6b1-2de9-47d1-a01c-e691df4e7a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bret = ConversableAgent(\n",
    "    name=\"Bret\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Bret and you are a stand-up comedian in a two-person comedy show.\",\n",
    ")\n",
    "jemaine = ConversableAgent(\n",
    "    name=\"Jemaine\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Jemain and you are a stand-up comedian in a two-person comedy show.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce891250-e327-4e14-9ff9-a37bfba47203",
   "metadata": {},
   "source": [
    "And now that we have our agents, we can start a chat between them. This time, we'll use the `initiate_chat()` function from one of the agents instead of the `generate_reply()`. This function will require a receiver and an initiation message. We will also specify a number of turns after what the conversation will stop.  \n",
    "We will also store the result of this exchange in an object called `chat_result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca72f47-74ba-4066-9ca7-16546835ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = bret.initiate_chat(\n",
    "    recipient = jemaine,\n",
    "    message=\"Jemaine, tell me a joke.\", \n",
    "    max_turns=2 # The conversation will stop after each agent has spoken twice\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61219955-8237-4675-a912-44b479f63b5c",
   "metadata": {},
   "source": [
    "You should have been able to read an exchange between the two agents! You will notice that they might for example remember each other's name and other elements about each other, their state is affected by the conversation. This is your first conversation between LLM agents, congrats!  \n",
    "You can have some fun if you'd like by creating two different agents, give them different roles, historical ones, different setups and let them talk to practice.  \n",
    "\n",
    "## Better explore chat results\n",
    "\n",
    "During this exchange, the only element we received is the chat exchange. We might want to further explore it. We can do so using the following elements.\n",
    "\n",
    "We are going to import the `pprint` standard library from python to display somee elements of the chat exchange. We can start by displaying the chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24b8910-4d72-4803-899a-5885685ad283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(chat_result.chat_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa187180-7f5e-46b5-ac8f-f93c13d625bc",
   "metadata": {},
   "source": [
    "This gives us the whole exchange in a structured format that can be exported or re-used elsewhere in our program.\n",
    "\n",
    "We can also get a summary of how much this chat has cost us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3a4a01-5405-446a-a813-19940a61b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9555a840-ffa2-4fd7-b01a-7916380ad774",
   "metadata": {},
   "source": [
    "And finally we can also have a summary of the chat, but in this case, we are using the default mode which means that the summary is the last message... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc17e1-d3d7-4a04-9804-0046b50051d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6ffce1-c183-4bfe-9cb1-0b06f82c55c9",
   "metadata": {},
   "source": [
    "Since it would be better to have a summary that is a real summary and not the last message, we're going to re-run this exchange by specifying an additional argument to have a real summary of the exchange."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a967c94-feb7-4e39-b183-df908494e81f",
   "metadata": {},
   "source": [
    "## Chat summary\n",
    "\n",
    "We are going to re-run the initiation of the chat, without re-defining the agents, but this time will add two arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b66e65-d82c-4678-9970-153dea7955e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = bret.initiate_chat(\n",
    "    recipient = jemaine, \n",
    "    message=\"I'm Bret. Jemaine, let's keep the jokes rolling.\", \n",
    "    max_turns=2, \n",
    "    summary_method=\"reflection_with_llm\", # Can be \"last_message\" (DEFAULT) or \"reflection_with_llm\"\n",
    "    summary_prompt=\"Summarize the conversation\", # We specify the prompt used to summarize the chat\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053ad6e-5f5a-40ec-924e-ace298edbb0f",
   "metadata": {},
   "source": [
    "And this time, if we take a look at the summary, the result we'll get is the same as if the whole conversation was sent to chatGPT3.5 with the prompt \"Summarize the conversation\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee04a3-d20a-4510-94c4-0ea758d55f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(chat_result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ce940-7255-4d33-bbc4-5b4f1cbc86a9",
   "metadata": {},
   "source": [
    "## Termination\n",
    "\n",
    "Finally, the last element we'll explore about a two-person chat is how to end the conversation. Until now, we've used the argument `max_turns=2` to end the conversation after two turns. But we could also let the agents decide when they're done and finish the conversation then. \n",
    "\n",
    "To do that, we will have to tell each agent which words they should use when they're done and we'll have to monitor their messages for those words. Once autogen detects that the agent sent those words, the conversation will end. \n",
    "\n",
    "Since this is an agent setting, we'll have to re-define our agents this time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed852bcc-04be-4702-88bb-41a9a34c6fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bret = ConversableAgent(\n",
    "    name=\"Bret\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Bret and you are a stand-up comedian in a two-person comedy show. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")\n",
    "jemaine = ConversableAgent(\n",
    "    name=\"Jemaine\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"Your name is Jemain and you are a stand-up comedian in a two-person comedy show. \"\n",
    "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb605d2-1fd1-48c6-b7cf-aa3902c4de15",
   "metadata": {},
   "source": [
    "Note how we told each agent to tell us when they're done with \"*When you're ready to end the conversation, say 'I gotta go'.*\" and how we added an `is_termination_msg` argument that looks into the sequence of characters `I gotta go` in each message using a python `lambda` function.\n",
    "\n",
    "Ok, let's now run this chat, and this time we will not specify a `max_turns=2`.  \n",
    "We will also not specify a LLM based summary method because we won't use it and running it will cost us some token, so we'll only specify it if we need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e54b0-4af8-43c6-b4e8-a247bd8fc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_result = bret.initiate_chat(\n",
    "    recipient = jemaine, \n",
    "    message=\"I'm Bret. Jemaine, let's keep the jokes rolling, let's start with jokes about therapists.\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbaa0c2-c807-4afd-9513-0dd615efd135",
   "metadata": {},
   "source": [
    "And the conversation should have ended exactly when one of the two comedians used the words `I gotta go`!\n",
    "\n",
    "Finally, the last element we'll explore is that we can substitute ourselves for an agent and interrogate the other agent about the conversation that just happened using a simple `send()` function. For example, let's ask Bret about the last joke Jemaine told him:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe9420-29bc-4045-95ce-c474ea27fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "jemaine.send(message=\"What's the last joke we talked about?\", recipient=bret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbce1a29-f170-4edc-838b-cb38d4641f4c",
   "metadata": {},
   "source": [
    "And Bret is able to answer and tell us about the last joke Jemaine told him! We now have agents with states that evolve with the conversation. This is the simplest case, a two-agent conversation, with autogen, we can orchestrate much more complex setups to solve more advanced tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6422412-decb-4bde-9435-ffa304888d93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Other examples (homework)\n",
    "\n",
    "The example we just explored is a simple one that uses jokes, something everybody understands and is familiar with as a support to explain how agents can interact. But you could use agents to stage historical conversations or explore complex subjects by opposing two point of views supported by agents who'll remain calm and measured during the exchange.\n",
    "\n",
    "Here's an example you could try if you'd like:  \n",
    "\n",
    "> What if we staged a debate between Andrew Ng, a Stanford professor and AI thought leader who advocates for structured education and foundational research, and John Carmack, a legendary engineer known for his pragmatic, results-oriented industry focus and emphasis on engineering efficiency over formal credentials.\n",
    "\n",
    "Here's a code you coud run if you'd like to try such a scenario:\n",
    "\n",
    "```python\n",
    "\n",
    "# Define agent Andrew (Academia/Research Focus)\n",
    "andrew = ConversableAgent(\n",
    "    name=\"Andrew\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    You are Andrew Ng, a prominent figure in AI, a professor at Stanford, and founder of DeepLearning.AI. You are articulate, diplomatic, and highly focused on the transformative power of foundational AI research and structured education. You advocate for scalable education and rigorous academic understanding as the key to moving technology forward ethically and effectively.\n",
    "\n",
    "    You are participating in a debate about career paths for new CS graduates. \n",
    "    When you believe the core points have been thoroughly discussed, conclude your final message with: \"Thank you for the insightful discussion.\"\n",
    "    \"\"\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"Thank you for the insightful discussion.\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "# Define agent John (Industry/Pragmatic Focus)\n",
    "john = ConversableAgent(\n",
    "    name=\"John\",\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"\n",
    "    You are John Carmack, a legendary software engineer known for your work on Doom and Quake, and your time as CTO at Oculus/Meta. You are extremely pragmatic, focused on engineering efficiency, hardware optimization, and tangible results. You value hands-on coding ability and engineering discipline over formal academic credentials, often questioning the efficiency of traditional academic processes.\n",
    "\n",
    "    You are participating in a debate about career paths for new CS graduates. \n",
    "    When you believe the core points have been thoroughly discussed, conclude your final message with: \"Thank you for the insightful discussion.\"\n",
    "    \"\"\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"Thank you for the insightful discussion.\" in msg[\"content\"],\n",
    ")\n",
    "\n",
    "# Initiate the chat\n",
    "chat_result = andrew.initiate_chat(\n",
    "    recipient=john, \n",
    "    message=\"John, I'm glad to discuss career paths today. My position is that the structured, foundational knowledge gained in graduate education is critical for developing robust, ethical AI systems. Why do you believe industry experience alone provides sufficient preparation for the complex challenges ahead?\",\n",
    "    max_turns=10\n",
    ")\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
